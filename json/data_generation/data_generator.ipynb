{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LucaH\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"paraloq/json_data_extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'topic', 'item_id', 'schema', 'item', 'text', 'medium', '__index_level_0__'],\n",
       "        num_rows: 484\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"items\", exist_ok=True)\n",
    "\n",
    "# Extract the \"item\" and \"title\" features from the dataset\n",
    "items = ds[\"train\"][\"item\"]\n",
    "titles = ds[\"train\"][\"title\"]\n",
    "\n",
    "# Select 10 random items and their corresponding titles\n",
    "random_indices = random.sample(range(len(items)), 10)\n",
    "random_items = [items[i] for i in random_indices]\n",
    "random_titles = [titles[i] for i in random_indices]\n",
    "\n",
    "\n",
    "# Write each item to a separate .json file with formatting\n",
    "for i, (item, title) in enumerate(zip(random_items, random_titles)):\n",
    "    item_dict = json.loads(item)  # Parse the JSON string into a dictionary\n",
    "    sanitized_title = \"\".join(c if c.isalnum() else \"_\" for c in title)  # Sanitize the title for file naming\n",
    "    with open(f\"items/{i+1}_{sanitized_title}.json\", \"w\") as f:\n",
    "        json.dump(item_dict, f, indent=4)  # Write the dictionary as formatted JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10_Shopping_Cart_Item_instruction.md from 10_Shopping_Cart_Item.json\n",
      "Generated 1_Blockchain_Smart_Contract_instruction.md from 1_Blockchain_Smart_Contract.json\n",
      "Generated 2_Shopping_Cart_Discount_instruction.md from 2_Shopping_Cart_Discount.json\n",
      "Generated 3_Customer_Feedback_instruction.md from 3_Customer_Feedback.json\n",
      "Generated 4_Clinical_Trial_Information_instruction.md from 4_Clinical_Trial_Information.json\n",
      "Generated 5_Raw_Material_Lot_Tracking_Data_instruction.md from 5_Raw_Material_Lot_Tracking_Data.json\n",
      "Generated 6_Traveler_s_Health_Insurance_instruction.md from 6_Traveler_s_Health_Insurance.json\n",
      "Generated 7_Film_Production_Crew_instruction.md from 7_Film_Production_Crew.json\n",
      "Generated 8_Medical_Diagnosis_Report_instruction.md from 8_Medical_Diagnosis_Report.json\n",
      "Generated 9_Emergency_Medical_Contact_instruction.md from 9_Emergency_Medical_Contact.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ollama\n",
    "\n",
    "# Directory where the JSON files are stored\n",
    "json_directory = \"items\"\n",
    "\n",
    "# Directory where the generated .md files will be stored (if you want to keep them in the same folder)\n",
    "output_directory = \"items\"\n",
    "\n",
    "# Path to the file where the prompt is stored\n",
    "prompt_file_path = \"prompt_to_generate_instructions.md\"\n",
    "\n",
    "# Function to load the prompt from the file\n",
    "def load_prompt():\n",
    "    with open(prompt_file_path, \"r\") as prompt_file:\n",
    "        return prompt_file.read()\n",
    "\n",
    "# Function to call the local LLM via Ollama\n",
    "def generate_markdown_from_json(json_content, prompt_template):\n",
    "    # Insert the JSON content into the prompt\n",
    "    final_prompt = prompt_template.replace(\"{{json_content}}\", json.dumps(json_content, indent=4))\n",
    "    \n",
    "    # Call the LLM using ollama's chat function\n",
    "    try:\n",
    "        response = ollama.chat(model='llama3.1:8b', messages=[{'role': 'user', 'content': final_prompt}])\n",
    "        return response['message']['content']  # Assuming this contains the Markdown content\n",
    "    except ollama.ResponseError as e:\n",
    "        raise Exception(f\"Error while generating markdown: {e.error}\")\n",
    "\n",
    "# Load the prompt from the file\n",
    "prompt_template = load_prompt()\n",
    "\n",
    "# Loop over all JSON files in the directory\n",
    "for filename in os.listdir(json_directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        json_path = os.path.join(json_directory, filename)\n",
    "        \n",
    "        # Load the JSON content\n",
    "        with open(json_path, \"r\") as json_file:\n",
    "            json_content = json.load(json_file)\n",
    "        \n",
    "        # Generate markdown content using the LLM\n",
    "        markdown_content = generate_markdown_from_json(json_content, prompt_template)\n",
    "        \n",
    "        # Create the output Markdown file\n",
    "        output_filename = f\"{os.path.splitext(filename)[0]}_instruction.md\"\n",
    "        output_path = os.path.join(output_directory, output_filename)\n",
    "        \n",
    "        # Write the markdown content to the .md file\n",
    "        with open(output_path, \"w\") as md_file:\n",
    "            md_file.write(markdown_content)\n",
    "        \n",
    "        print(f\"Generated {output_filename} from {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10_Shopping_Cart_Item_solution.json by applying instructions to 10_Shopping_Cart_Item.json\n",
      "Generated 1_Blockchain_Smart_Contract_solution.json by applying instructions to 1_Blockchain_Smart_Contract.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ollama\n",
    "\n",
    "# Directory where the JSON files are stored\n",
    "json_directory = \"items\"\n",
    "\n",
    "# Path to the file where the prompt is stored\n",
    "prompt_file_path = \"prompt_to_generate_solution.md\"\n",
    "\n",
    "# Function to load the prompt from the file\n",
    "def load_prompt():\n",
    "    with open(prompt_file_path, \"r\") as prompt_file:\n",
    "        return prompt_file.read()\n",
    "\n",
    "# Function to load the instruction from the Markdown file\n",
    "def load_instruction(instruction_file_path):\n",
    "    with open(instruction_file_path, \"r\") as instruction_file:\n",
    "        return instruction_file.read()\n",
    "\n",
    "# Function to call the local LLM via Ollama\n",
    "def apply_instructions_to_json(json_content, instruction_content, prompt_template):\n",
    "    # Insert the JSON content and instruction content into the prompt\n",
    "    final_prompt = prompt_template.replace(\"{{json_content}}\", json.dumps(json_content, indent=4))\n",
    "    final_prompt = final_prompt.replace(\"{{instruction_content}}\", instruction_content)\n",
    "\n",
    "    # Call the LLM using Ollama's chat function\n",
    "    try:\n",
    "        response = ollama.chat(model='deepseek-coder:6.7b', messages=[{'role': 'user', 'content': final_prompt}])\n",
    "        output_text = response['message']['content']\n",
    "\n",
    "        # Attempt to parse the output as JSON\n",
    "        try:\n",
    "            # Remove any code fences or extra text\n",
    "            json_start = output_text.find('{')\n",
    "            json_end = output_text.rfind('}') + 1\n",
    "            json_str = output_text[json_start:json_end]\n",
    "\n",
    "            modified_json = json.loads(json_str)\n",
    "            return modified_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise Exception(f\"Failed to parse LLM output as JSON. Error: {e}\\nLLM Output:\\n{output_text}\")\n",
    "    except ollama.ResponseError as e:\n",
    "        raise Exception(f\"Error while applying instructions: {e.error}\")\n",
    "\n",
    "# Load the prompt from the file\n",
    "prompt_template = load_prompt()\n",
    "\n",
    "# Loop over all JSON files in the directory\n",
    "for filename in os.listdir(json_directory):\n",
    "    if filename.endswith(\".json\") and not filename.endswith(\"_solution.json\"):\n",
    "        json_path = os.path.join(json_directory, filename)\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        instruction_filename = f\"{base_name}_instruction.md\"\n",
    "        instruction_path = os.path.join(json_directory, instruction_filename)\n",
    "\n",
    "        # Check if the instruction file exists\n",
    "        if not os.path.exists(instruction_path):\n",
    "            print(f\"Instruction file {instruction_filename} not found for {filename}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Load the JSON content\n",
    "        with open(json_path, \"r\") as json_file:\n",
    "            json_content = json.load(json_file)\n",
    "\n",
    "        # Load the instruction content\n",
    "        instruction_content = load_instruction(instruction_path)\n",
    "\n",
    "        # Generate the modified JSON using the LLM\n",
    "        modified_json = apply_instructions_to_json(json_content, instruction_content, prompt_template)\n",
    "\n",
    "        # Create the output JSON file\n",
    "        output_filename = f\"{base_name}_solution.json\"\n",
    "        output_path = os.path.join(json_directory, output_filename)\n",
    "\n",
    "        # Write the modified JSON content to the .json file\n",
    "        with open(output_path, \"w\") as json_file:\n",
    "            json.dump(modified_json, json_file, indent=4)\n",
    "\n",
    "        print(f\"Generated {output_filename} by applying instructions to {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
