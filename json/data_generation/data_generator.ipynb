{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LucaH\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"paraloq/json_data_extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'topic', 'item_id', 'schema', 'item', 'text', 'medium', '__index_level_0__'],\n",
       "        num_rows: 484\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"items\", exist_ok=True)\n",
    "\n",
    "# Extract the \"item\" and \"title\" features from the dataset\n",
    "items = ds[\"train\"][\"item\"]\n",
    "titles = ds[\"train\"][\"title\"]\n",
    "\n",
    "# Select 10 random items and their corresponding titles\n",
    "random_indices = random.sample(range(len(items)), 100)\n",
    "random_items = [items[i] for i in random_indices]\n",
    "random_titles = [titles[i] for i in random_indices]\n",
    "\n",
    "# Write each item to a separate .json file with formatting\n",
    "for i, (item, title) in enumerate(zip(random_items, random_titles)):\n",
    "    item_dict = json.loads(item)  # Parse the JSON string into a dictionary\n",
    "    sanitized_title = \"\".join(c if c.isalnum() else \"_\" for c in title)  # Sanitize the title for file naming\n",
    "    file_number = f\"{i+1:03}\"  # Format the running number with leading zeros\n",
    "    with open(f\"items/{file_number}_{sanitized_title}.json\", \"w\") as f:\n",
    "        json.dump(item_dict, f, indent=4)  # Write the dictionary as formatted JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100_SSL_Certificate_instruction.md from 100_SSL_Certificate.json\n",
      "Generated 10_Corporate_Financial_Risk_Management_Plan_instruction.md from 10_Corporate_Financial_Risk_Management_Plan.json\n",
      "Generated 11_Job_Application_instruction.md from 11_Job_Application.json\n",
      "Generated 12_Corporate_Whistleblower_Policy_instruction.md from 12_Corporate_Whistleblower_Policy.json\n",
      "Generated 13_Pharmacy_Prescription_Order_instruction.md from 13_Pharmacy_Prescription_Order.json\n",
      "Generated 14_Blog_Post_instruction.md from 14_Blog_Post.json\n",
      "Generated 15_Text_Message_instruction.md from 15_Text_Message.json\n",
      "Generated 16_Vaccination_Record_instruction.md from 16_Vaccination_Record.json\n",
      "Generated 17_Hotel_Room_Service_Charges_instruction.md from 17_Hotel_Room_Service_Charges.json\n",
      "Generated 18_Quality_Control_Inspection_Report_instruction.md from 18_Quality_Control_Inspection_Report.json\n",
      "Generated 19_Cloud_Service_Subscription_instruction.md from 19_Cloud_Service_Subscription.json\n",
      "Generated 1_Company_Review_instruction.md from 1_Company_Review.json\n",
      "Generated 20_Production_Line_Configuration_instruction.md from 20_Production_Line_Configuration.json\n",
      "Generated 21_Author_Book_Signing_Event_instruction.md from 21_Author_Book_Signing_Event.json\n",
      "Generated 22_Data_Encryption_Key_instruction.md from 22_Data_Encryption_Key.json\n",
      "Generated 23_Pharmacy_Dispensing_Record_instruction.md from 23_Pharmacy_Dispensing_Record.json\n",
      "Generated 24_Business_Non_Disclosure_Agreement_instruction.md from 24_Business_Non_Disclosure_Agreement.json\n",
      "Generated 25_Movie_Trailer_instruction.md from 25_Movie_Trailer.json\n",
      "Generated 26_Airport_Parking_Reservation_instruction.md from 26_Airport_Parking_Reservation.json\n",
      "Generated 27_Bookstore_Membership_Program_instruction.md from 27_Bookstore_Membership_Program.json\n",
      "Generated 28_To_Do_List_instruction.md from 28_To_Do_List.json\n",
      "Generated 29_TV_Show_Ratings_instruction.md from 29_TV_Show_Ratings.json\n",
      "Generated 2_IT_Disaster_Recovery_Plan_instruction.md from 2_IT_Disaster_Recovery_Plan.json\n",
      "Generated 30_Medical_Research_Grant_Application_instruction.md from 30_Medical_Research_Grant_Application.json\n",
      "Generated 31_Podcast_Episode_Timestamps_instruction.md from 31_Podcast_Episode_Timestamps.json\n",
      "Generated 32_Web_Hosting_Service_Agreement_instruction.md from 32_Web_Hosting_Service_Agreement.json\n",
      "Generated 33_Emergency_Medical_Response_Plan_instruction.md from 33_Emergency_Medical_Response_Plan.json\n",
      "Generated 34_Network_Port_Mapping_instruction.md from 34_Network_Port_Mapping.json\n",
      "Generated 35_Materials_Handling_Instructions_instruction.md from 35_Materials_Handling_Instructions.json\n",
      "Generated 36_Travel_Itinerary_Change_Request_instruction.md from 36_Travel_Itinerary_Change_Request.json\n",
      "Generated 37_Corporate_Governance_Policy_instruction.md from 37_Corporate_Governance_Policy.json\n",
      "Generated 38_Podcast_Listener_Survey_instruction.md from 38_Podcast_Listener_Survey.json\n",
      "Generated 39_Movie_Marketing_Campaign_instruction.md from 39_Movie_Marketing_Campaign.json\n",
      "Generated 3_Lost_and_Found_at_Hotel_instruction.md from 3_Lost_and_Found_at_Hotel.json\n",
      "Generated 40_Clinical_Trial_Participant_Informed_Consent_instruction.md from 40_Clinical_Trial_Participant_Informed_Consent.json\n",
      "Generated 41_Payment_Confirmation_instruction.md from 41_Payment_Confirmation.json\n",
      "Generated 42_Hotel_Reservation_instruction.md from 42_Hotel_Reservation.json\n",
      "Generated 43_Healthcare_Facility_Floor_Plan_instruction.md from 43_Healthcare_Facility_Floor_Plan.json\n",
      "Generated 44_Shopping_Cart_instruction.md from 44_Shopping_Cart.json\n",
      "Generated 45_Medical_Research_Data_Access_Request_instruction.md from 45_Medical_Research_Data_Access_Request.json\n",
      "Generated 46_Product_Specification_Sheet_instruction.md from 46_Product_Specification_Sheet.json\n",
      "Generated 47_Music_Festival_Camping_Rules_instruction.md from 47_Music_Festival_Camping_Rules.json\n",
      "Generated 48_Product_Rating_and_Review_Export_instruction.md from 48_Product_Rating_and_Review_Export.json\n",
      "Generated 49_Purchase_Order_instruction.md from 49_Purchase_Order.json\n",
      "Generated 4_Corporate_Supplier_Evaluation_Report_instruction.md from 4_Corporate_Supplier_Evaluation_Report.json\n",
      "Generated 50_Corporate_Talent_Acquisition_Strategy_instruction.md from 50_Corporate_Talent_Acquisition_Strategy.json\n",
      "Generated 51_Software_License_Key_instruction.md from 51_Software_License_Key.json\n",
      "Generated 52_Game_Character_Profile_instruction.md from 52_Game_Character_Profile.json\n",
      "Generated 53_Medical_Test_Kit_Instructions_instruction.md from 53_Medical_Test_Kit_Instructions.json\n",
      "Generated 54_Product_Recommendation_instruction.md from 54_Product_Recommendation.json\n",
      "Generated 55_Travel_Expense_Reimbursement_instruction.md from 55_Travel_Expense_Reimbursement.json\n",
      "Generated 56_Business_Budget_Report_instruction.md from 56_Business_Budget_Report.json\n",
      "Generated 57_Corporate_Sustainability_Report_instruction.md from 57_Corporate_Sustainability_Report.json\n",
      "Generated 58_Production_Yield_Report_instruction.md from 58_Production_Yield_Report.json\n",
      "Generated 59_Podcast_Transcript_instruction.md from 59_Podcast_Transcript.json\n",
      "Generated 5_Shopping_Cart_Guest_Checkout_instruction.md from 5_Shopping_Cart_Guest_Checkout.json\n",
      "Generated 60_Production_Line_Changeover_Instructions_instruction.md from 60_Production_Line_Changeover_Instructions.json\n",
      "Generated 61_Bug_Report_instruction.md from 61_Bug_Report.json\n",
      "Generated 62_TV_Show_Merchandise_Catalog_instruction.md from 62_TV_Show_Merchandise_Catalog.json\n",
      "Generated 63_Employee_Benefits_Package_instruction.md from 63_Employee_Benefits_Package.json\n",
      "Generated 64_Product_Availability_Notification_instruction.md from 64_Product_Availability_Notification.json\n",
      "Generated 65_Business_Invoice_instruction.md from 65_Business_Invoice.json\n",
      "Generated 66_Business_Shareholder_Agreement_instruction.md from 66_Business_Shareholder_Agreement.json\n",
      "Generated 67_Product_Bill_of_Materials__BOM__instruction.md from 67_Product_Bill_of_Materials__BOM_.json\n",
      "Generated 68_Comic_Book_Variant_Cover_Art_instruction.md from 68_Comic_Book_Variant_Cover_Art.json\n",
      "Generated 69_Machine_Maintenance_History_instruction.md from 69_Machine_Maintenance_History.json\n",
      "Generated 6_Process_Flow_Diagram_instruction.md from 6_Process_Flow_Diagram.json\n",
      "Generated 70_Product_Price_Drop_Alert_instruction.md from 70_Product_Price_Drop_Alert.json\n",
      "Generated 71_Travel_Packing_List_instruction.md from 71_Travel_Packing_List.json\n",
      "Generated 72_Raw_Material_Lot_Tracking_Data_instruction.md from 72_Raw_Material_Lot_Tracking_Data.json\n",
      "Generated 73_Podcast_Advertiser_Agreement_instruction.md from 73_Podcast_Advertiser_Agreement.json\n",
      "Generated 74_Supplier_Quality_Improvement_Plan_instruction.md from 74_Supplier_Quality_Improvement_Plan.json\n",
      "Generated 75_Supplier_Non_Conformance_Report_instruction.md from 75_Supplier_Non_Conformance_Report.json\n",
      "Generated 76_Hotel_Room_Check_Out_instruction.md from 76_Hotel_Room_Check_Out.json\n",
      "Generated 77_Patient_Consent_Form_instruction.md from 77_Patient_Consent_Form.json\n",
      "Generated 78_Flight_Upgrade_Request_instruction.md from 78_Flight_Upgrade_Request.json\n",
      "Generated 79_Cloud_Service_SLA__Service_Level_Agreement__instruction.md from 79_Cloud_Service_SLA__Service_Level_Agreement_.json\n",
      "Generated 7_Factory_Waste_Reduction_Plan_instruction.md from 7_Factory_Waste_Reduction_Plan.json\n",
      "Generated 80_Medical_Device_User_Manual_instruction.md from 80_Medical_Device_User_Manual.json\n",
      "Generated 81_Cybersecurity_Best_Practices_Guide_instruction.md from 81_Cybersecurity_Best_Practices_Guide.json\n",
      "Generated 82_IT_Asset_Inventory_instruction.md from 82_IT_Asset_Inventory.json\n",
      "Generated 83_Traveler_s_First_Aid_Kit_Checklist_instruction.md from 83_Traveler_s_First_Aid_Kit_Checklist.json\n",
      "Generated 84_Customer_Account_Password_Reset_instruction.md from 84_Customer_Account_Password_Reset.json\n",
      "Generated 85_Calendar_Event_instruction.md from 85_Calendar_Event.json\n",
      "Generated 86_Travel_Sim_Card_Activation_instruction.md from 86_Travel_Sim_Card_Activation.json\n",
      "Generated 87_Patient_Medical_History_instruction.md from 87_Patient_Medical_History.json\n",
      "Generated 88_Payment_Transaction_instruction.md from 88_Payment_Transaction.json\n",
      "Generated 89_Art_Gallery_Membership_Benefits_instruction.md from 89_Art_Gallery_Membership_Benefits.json\n",
      "Generated 8_Flight_Boarding_instruction.md from 8_Flight_Boarding.json\n",
      "Generated 90_Data_Retention_Policy_instruction.md from 90_Data_Retention_Policy.json\n",
      "Generated 91_Movie_Soundtrack_instruction.md from 91_Movie_Soundtrack.json\n",
      "Generated 92_Prescription_Medication_instruction.md from 92_Prescription_Medication.json\n",
      "Generated 93_Product_Availability_Date_instruction.md from 93_Product_Availability_Date.json\n",
      "Generated 94_Video_Game_instruction.md from 94_Video_Game.json\n",
      "Generated 95_Notification_instruction.md from 95_Notification.json\n",
      "Generated 96_Calendar_Entry_instruction.md from 96_Calendar_Entry.json\n",
      "Generated 97_Supplier_Price_Quotation_instruction.md from 97_Supplier_Price_Quotation.json\n",
      "Generated 98_Public_Health_Report_instruction.md from 98_Public_Health_Report.json\n",
      "Generated 99_Travel_Activity_Reservation_instruction.md from 99_Travel_Activity_Reservation.json\n",
      "Generated 9_Emergency_Medical_Contact_instruction.md from 9_Emergency_Medical_Contact.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ollama\n",
    "\n",
    "# Directory where the JSON files are stored\n",
    "json_directory = \"items\"\n",
    "\n",
    "# Directory where the generated .md files will be stored (if you want to keep them in the same folder)\n",
    "output_directory = \"items\"\n",
    "\n",
    "# Path to the file where the prompt is stored\n",
    "prompt_file_path = \"prompt_to_generate_instructions.md\"\n",
    "\n",
    "# Function to load the prompt from the file\n",
    "def load_prompt():\n",
    "    with open(prompt_file_path, \"r\") as prompt_file:\n",
    "        return prompt_file.read()\n",
    "\n",
    "# Function to call the local LLM via Ollama\n",
    "def generate_markdown_from_json(json_content, prompt_template):\n",
    "    # Insert the JSON content into the prompt\n",
    "    final_prompt = prompt_template.replace(\"{{json_content}}\", json.dumps(json_content, indent=4))\n",
    "    \n",
    "    # Call the LLM using ollama's chat function\n",
    "    try:\n",
    "        response = ollama.chat(model='llama3.1:8b', messages=[{'role': 'user', 'content': final_prompt}])\n",
    "        return response['message']['content']  # Assuming this contains the Markdown content\n",
    "    except ollama.ResponseError as e:\n",
    "        raise Exception(f\"Error while generating markdown: {e.error}\")\n",
    "\n",
    "# Load the prompt from the file\n",
    "prompt_template = load_prompt()\n",
    "\n",
    "# Loop over all JSON files in the directory\n",
    "for filename in os.listdir(json_directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        json_path = os.path.join(json_directory, filename)\n",
    "        \n",
    "        # Load the JSON content\n",
    "        with open(json_path, \"r\") as json_file:\n",
    "            json_content = json.load(json_file)\n",
    "        \n",
    "        # Generate markdown content using the LLM\n",
    "        markdown_content = generate_markdown_from_json(json_content, prompt_template)\n",
    "        \n",
    "        # Create the output Markdown file\n",
    "        output_filename = f\"{os.path.splitext(filename)[0]}_instruction.md\"\n",
    "        output_path = os.path.join(output_directory, output_filename)\n",
    "        \n",
    "        # Write the markdown content to the .md file\n",
    "        with open(output_path, \"w\") as md_file:\n",
    "            md_file.write(markdown_content)\n",
    "        \n",
    "        print(f\"Generated {output_filename} from {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ollama\n",
    "\n",
    "# Directory where the JSON files are stored\n",
    "json_directory = \"items\"\n",
    "\n",
    "# Path to the file where the prompt is stored\n",
    "prompt_file_path = \"prompt_to_generate_solution.md\"\n",
    "\n",
    "# Function to load the prompt from the file\n",
    "def load_prompt():\n",
    "    with open(prompt_file_path, \"r\") as prompt_file:\n",
    "        return prompt_file.read()\n",
    "\n",
    "# Function to load the instruction from the Markdown file\n",
    "def load_instruction(instruction_file_path):\n",
    "    with open(instruction_file_path, \"r\") as instruction_file:\n",
    "        return instruction_file.read()\n",
    "\n",
    "# Function to call the local LLM via Ollama\n",
    "def apply_instructions_to_json(json_content, instruction_content, prompt_template):\n",
    "    # Insert the JSON content and instruction content into the prompt\n",
    "    final_prompt = prompt_template.replace(\"{{json_content}}\", json.dumps(json_content, indent=4))\n",
    "    final_prompt = final_prompt.replace(\"{{instruction_content}}\", instruction_content)\n",
    "\n",
    "    # Call the LLM using Ollama's chat function\n",
    "    try:\n",
    "        response = ollama.chat(model='llama3.1:8b', messages=[{'role': 'user', 'content': final_prompt}])\n",
    "        output_text = response['message']['content']\n",
    "\n",
    "        # Attempt to parse the output as JSON\n",
    "        try:\n",
    "            # Remove any code fences or extra text\n",
    "            json_start = output_text.find('{')\n",
    "            json_end = output_text.rfind('}') + 1\n",
    "            json_str = output_text[json_start:json_end]\n",
    "\n",
    "            modified_json = json.loads(json_str)\n",
    "            return modified_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise Exception(f\"Failed to parse LLM output as JSON. Error: {e}\\nLLM Output:\\n{output_text}\")\n",
    "    except ollama.ResponseError as e:\n",
    "        raise Exception(f\"Error while applying instructions: {e.error}\")\n",
    "\n",
    "# Load the prompt from the file\n",
    "prompt_template = load_prompt()\n",
    "\n",
    "# Loop over all JSON files in the directory\n",
    "for filename in os.listdir(json_directory):\n",
    "    if filename.endswith(\".json\") and not filename.endswith(\"_solution.json\"):\n",
    "        try:\n",
    "            json_path = os.path.join(json_directory, filename)\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            instruction_filename = f\"{base_name}_instruction.md\"\n",
    "            instruction_path = os.path.join(json_directory, instruction_filename)\n",
    "\n",
    "            # Check if the corresponding solution file already exists\n",
    "            solution_filename = f\"{base_name}_solution.json\"\n",
    "            solution_path = os.path.join(json_directory, solution_filename)\n",
    "\n",
    "            if os.path.exists(solution_path):\n",
    "                print(f\"Solution file {solution_filename} already exists for {filename}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Check if the instruction file exists\n",
    "            if not os.path.exists(instruction_path):\n",
    "                print(f\"Instruction file {instruction_filename} not found for {filename}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Load the JSON content\n",
    "            with open(json_path, \"r\") as json_file:\n",
    "                json_content = json.load(json_file)\n",
    "\n",
    "            # Load the instruction content\n",
    "            instruction_content = load_instruction(instruction_path)\n",
    "\n",
    "            # Generate the modified JSON using the LLM\n",
    "            modified_json = apply_instructions_to_json(json_content, instruction_content, prompt_template)\n",
    "\n",
    "            # Create the output JSON file\n",
    "            output_path = os.path.join(json_directory, solution_filename)\n",
    "\n",
    "            # Write the modified JSON content to the .json file\n",
    "            with open(output_path, \"w\") as json_file:\n",
    "                json.dump(modified_json, json_file, indent=4)\n",
    "\n",
    "            print(f\"Generated {solution_filename} by applying instructions to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {filename}: {e}\")\n",
    "            continue  # Continue to next iteration\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
